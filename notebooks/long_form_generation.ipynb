{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39ea4bed",
      "metadata": {
        "id": "39ea4bed",
        "outputId": "d0d22327-0b87-4e9f-d3ef-b5f824fad9d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/vatsaladitya/bark.git\n",
            "  Cloning https://github.com/vatsaladitya/bark.git to /tmp/pip-req-build-eqnd3t73\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/vatsaladitya/bark.git /tmp/pip-req-build-eqnd3t73\n",
            "  Resolved https://github.com/vatsaladitya/bark.git to commit 838b65af0cc10cb9d3fe7a5dc8facd69fa9ea3df\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting boto3 (from suno-bark==0.0.1a0)\n",
            "  Downloading boto3-1.38.23-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting encodec (from suno-bark==0.0.1a0)\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting funcy (from suno-bark==0.0.1a0)\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.14.1 in /usr/local/lib/python3.11/dist-packages (from suno-bark==0.0.1a0) (0.31.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from suno-bark==0.0.1a0) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from suno-bark==0.0.1a0) (1.15.3)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from suno-bark==0.0.1a0) (0.21.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from suno-bark==0.0.1a0) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from suno-bark==0.0.1a0) (4.67.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from suno-bark==0.0.1a0) (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (4.13.2)\n",
            "Collecting botocore<1.39.0,>=1.38.23 (from boto3->suno-bark==0.0.1a0)\n",
            "  Downloading botocore-1.38.23-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->suno-bark==0.0.1a0)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3->suno-bark==0.0.1a0)\n",
            "  Downloading s3transfer-0.13.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from encodec->suno-bark==0.0.1a0) (2.6.0+cu124)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from encodec->suno-bark==0.0.1a0) (0.8.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->suno-bark==0.0.1a0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->suno-bark==0.0.1a0) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->suno-bark==0.0.1a0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->suno-bark==0.0.1a0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->suno-bark==0.0.1a0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->suno-bark==0.0.1a0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->suno-bark==0.0.1a0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->suno-bark==0.0.1a0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->suno-bark==0.0.1a0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/vatsaladitya/bark.git\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "\n",
        "from IPython.display import Audio\n",
        "import nltk  # we'll use this to split into sentences\n",
        "import numpy as np\n",
        "\n",
        "from bark.generation import (\n",
        "    generate_text_semantic,\n",
        "    preload_models,\n",
        ")\n",
        "from bark.api import semantic_to_waveform\n",
        "from bark import generate_audio, SAMPLE_RATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "776964b6",
      "metadata": {
        "id": "776964b6"
      },
      "outputs": [],
      "source": [
        "preload_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d03f4d2",
      "metadata": {
        "id": "1d03f4d2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "74a025a4",
      "metadata": {
        "id": "74a025a4"
      },
      "source": [
        "# Simple Long-Form Generation\n",
        "We split longer text into sentences using `nltk` and generate the sentences one by one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57b06e2a",
      "metadata": {
        "id": "57b06e2a"
      },
      "outputs": [],
      "source": [
        "script = \"\"\"\n",
        "Hey, have you heard about this new text-to-audio model called \"Bark\"?\n",
        "Apparently, it's the most realistic and natural-sounding text-to-audio model\n",
        "out there right now. People are saying it sounds just like a real person speaking.\n",
        "I think it uses advanced machine learning algorithms to analyze and understand the\n",
        "nuances of human speech, and then replicates those nuances in its own speech output.\n",
        "It's pretty impressive, and I bet it could be used for things like audiobooks or podcasts.\n",
        "In fact, I heard that some publishers are already starting to use Bark to create audiobooks.\n",
        "It would be like having your own personal voiceover artist. I really think Bark is going to\n",
        "be a game-changer in the world of text-to-audio technology.\n",
        "\"\"\".replace(\"\\n\", \" \").strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f747f804",
      "metadata": {
        "id": "f747f804"
      },
      "outputs": [],
      "source": [
        "sentences = nltk.sent_tokenize(script)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17400a9b",
      "metadata": {
        "scrolled": true,
        "id": "17400a9b",
        "outputId": "d86e9572-4e7a-474d-d1a7-5c15571c6023"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 43.03it/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:06<00:00,  2.45it/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:04<00:00, 22.73it/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 33/33 [00:13<00:00,  2.52it/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 66.30it/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.46it/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:04<00:00, 20.99it/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 35/35 [00:14<00:00,  2.46it/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:03<00:00, 25.63it/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 29/29 [00:11<00:00,  2.50it/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:04<00:00, 23.90it/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 30/30 [00:12<00:00,  2.46it/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 53.24it/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 14/14 [00:05<00:00,  2.51it/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 50.63it/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 15/15 [00:05<00:00,  2.57it/s]\n"
          ]
        }
      ],
      "source": [
        "SPEAKER = \"v2/en_speaker_6\"\n",
        "silence = np.zeros(int(0.25 * SAMPLE_RATE))  # quarter second of silence\n",
        "\n",
        "pieces = []\n",
        "for sentence in sentences:\n",
        "    audio_array = generate_audio(sentence, history_prompt=SPEAKER)\n",
        "    pieces += [audio_array, silence.copy()]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04cf77f9",
      "metadata": {
        "id": "04cf77f9"
      },
      "outputs": [],
      "source": [
        "Audio(np.concatenate(pieces), rate=SAMPLE_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac2d4625",
      "metadata": {
        "id": "ac2d4625"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6d13249b",
      "metadata": {
        "id": "6d13249b"
      },
      "source": [
        "# $ \\\\ $"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdfc8bf5",
      "metadata": {
        "id": "cdfc8bf5"
      },
      "source": [
        "# Advanced Long-Form Generation\n",
        "Somtimes Bark will hallucinate a little extra audio at the end of the prompt.\n",
        "We can solve this issue by lowering the threshold for bark to stop generating text.\n",
        "We use the `min_eos_p` kwarg in `generate_text_semantic`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62807fd0",
      "metadata": {
        "id": "62807fd0",
        "outputId": "c5b80c81-ecdc-4e9f-a98f-05ed6159eefd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 38.05it/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 18/18 [00:07<00:00,  2.46it/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:03<00:00, 32.28it/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 21/21 [00:08<00:00,  2.54it/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 55.78it/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 14/14 [00:05<00:00,  2.57it/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 14.73it/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 35/35 [00:14<00:00,  2.47it/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 40.29it/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 18/18 [00:07<00:00,  2.56it/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:03<00:00, 32.92it/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 20/20 [00:08<00:00,  2.47it/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 68.87it/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 12/12 [00:04<00:00,  2.62it/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 47.64it/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 15/15 [00:06<00:00,  2.46it/s]\n"
          ]
        }
      ],
      "source": [
        "GEN_TEMP = 0.6\n",
        "SPEAKER = \"v2/en_speaker_6\"\n",
        "silence = np.zeros(int(0.25 * SAMPLE_RATE))  # quarter second of silence\n",
        "\n",
        "pieces = []\n",
        "for sentence in sentences:\n",
        "    semantic_tokens = generate_text_semantic(\n",
        "        sentence,\n",
        "        history_prompt=SPEAKER,\n",
        "        temp=GEN_TEMP,\n",
        "        min_eos_p=0.05,  # this controls how likely the generation is to end\n",
        "    )\n",
        "\n",
        "    audio_array = semantic_to_waveform(semantic_tokens, history_prompt=SPEAKER,)\n",
        "    pieces += [audio_array, silence.copy()]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "133fec46",
      "metadata": {
        "id": "133fec46"
      },
      "outputs": [],
      "source": [
        "Audio(np.concatenate(pieces), rate=SAMPLE_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eee9f5a",
      "metadata": {
        "id": "6eee9f5a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "be8e125e",
      "metadata": {
        "id": "be8e125e"
      },
      "source": [
        "# $ \\\\ $"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03a16c1b",
      "metadata": {
        "id": "03a16c1b"
      },
      "source": [
        "# Make a Long-Form Dialog with Bark"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06c5eff8",
      "metadata": {
        "id": "06c5eff8"
      },
      "source": [
        "### Step 1: Format a script and speaker lookup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5238b297",
      "metadata": {
        "id": "5238b297",
        "outputId": "241f0a90-085f-4ad9-f586-0ed73936e6f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Samantha: Hey, have you heard about this new text-to-audio model called \"Bark\"?',\n",
              " \"John: No, I haven't. What's so special about it?\",\n",
              " \"Samantha: Well, apparently it's the most realistic and natural-sounding text-to-audio model out there right now. People are saying it sounds just like a real person speaking.\",\n",
              " 'John: Wow, that sounds amazing. How does it work?',\n",
              " 'Samantha: I think it uses advanced machine learning algorithms to analyze and understand the nuances of human speech, and then replicates those nuances in its own speech output.',\n",
              " \"John: That's pretty impressive. Do you think it could be used for things like audiobooks or podcasts?\",\n",
              " 'Samantha: Definitely! In fact, I heard that some publishers are already starting to use Bark to create audiobooks. And I bet it would be great for podcasts too.',\n",
              " 'John: I can imagine. It would be like having your own personal voiceover artist.',\n",
              " 'Samantha: Exactly! I think Bark is going to be a game-changer in the world of text-to-audio technology.']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "speaker_lookup = {\"Samantha\": \"v2/en_speaker_9\", \"John\": \"v2/en_speaker_2\"}\n",
        "\n",
        "# Script generated by chat GPT\n",
        "script = \"\"\"\n",
        "Samantha: Hey, have you heard about this new text-to-audio model called \"Bark\"?\n",
        "\n",
        "John: No, I haven't. What's so special about it?\n",
        "\n",
        "Samantha: Well, apparently it's the most realistic and natural-sounding text-to-audio model out there right now. People are saying it sounds just like a real person speaking.\n",
        "\n",
        "John: Wow, that sounds amazing. How does it work?\n",
        "\n",
        "Samantha: I think it uses advanced machine learning algorithms to analyze and understand the nuances of human speech, and then replicates those nuances in its own speech output.\n",
        "\n",
        "John: That's pretty impressive. Do you think it could be used for things like audiobooks or podcasts?\n",
        "\n",
        "Samantha: Definitely! In fact, I heard that some publishers are already starting to use Bark to create audiobooks. And I bet it would be great for podcasts too.\n",
        "\n",
        "John: I can imagine. It would be like having your own personal voiceover artist.\n",
        "\n",
        "Samantha: Exactly! I think Bark is going to be a game-changer in the world of text-to-audio technology.\"\"\"\n",
        "script = script.strip().split(\"\\n\")\n",
        "script = [s.strip() for s in script if s]\n",
        "script"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee547efd",
      "metadata": {
        "id": "ee547efd"
      },
      "source": [
        "### Step 2: Generate the audio for every speaker turn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "203e5081",
      "metadata": {
        "id": "203e5081",
        "outputId": "4735fc73-7242-48cc-f7bd-4a15e15dd9d3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 34.03it/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 22/22 [00:08<00:00,  2.55it/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 71.58it/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.65it/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:04<00:00, 22.75it/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 33/33 [00:13<00:00,  2.53it/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 70.76it/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.63it/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:04<00:00, 20.46it/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 36/36 [00:14<00:00,  2.47it/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:04<00:00, 20.18it/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 37/37 [00:14<00:00,  2.51it/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:04<00:00, 23.04it/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 32/32 [00:12<00:00,  2.48it/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:01<00:00, 54.64it/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 14/14 [00:05<00:00,  2.58it/s]\n",
            "100%|██████████████████████████████████████████████████████████████████████| 100/100 [00:03<00:00, 31.71it/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████| 24/24 [00:09<00:00,  2.56it/s]\n"
          ]
        }
      ],
      "source": [
        "pieces = []\n",
        "silence = np.zeros(int(0.5*SAMPLE_RATE))\n",
        "for line in script:\n",
        "    speaker, text = line.split(\": \")\n",
        "    audio_array = generate_audio(text, history_prompt=speaker_lookup[speaker], )\n",
        "    pieces += [audio_array, silence.copy()]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c54bada",
      "metadata": {
        "id": "7c54bada"
      },
      "source": [
        "### Step 3: Concatenate all of the audio and play it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27a56842",
      "metadata": {
        "id": "27a56842"
      },
      "outputs": [],
      "source": [
        "Audio(np.concatenate(pieces), rate=SAMPLE_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1bc5877",
      "metadata": {
        "id": "a1bc5877"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}